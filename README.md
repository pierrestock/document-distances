# How to compute document similarities ? 

This repository is a Tensorflow implementation of a project consisting in computing document similarities. 

1. [Setup](#setup)

2. [Playing around](#playing-around)

3. [Going further](#going-further)

 
## Setup 

If you wish to usg this code, you will have to install the following package:
```
pip install gensim 
```
The pretrained word2vec model is available here: https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit (1.5 GB !)
[link text itself]: http://www.reddit.com
You can take a look at the iPython Notebook __toy_examples.ipynb__ that contains a very brief description of the algorithm, some fun properties of the word2vec metric and studies the influence of some parameters on some toy examples. 

## Playing around



## Going further

If you are interested in this topic, you can read the full pdf report (section __report__) that details some theoretical aspects, the methodology and the experimental results on large datasets. A bibliography is included if you want to go deeper on the theoretical side. 
